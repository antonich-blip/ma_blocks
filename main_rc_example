use eframe::egui;
use egui::{Align2, Color32, Pos2, Rect, RichText, Stroke, Vec2};
use egui_commonmark::{CommonMarkCache, CommonMarkViewer};

use rfd::FileDialog;
use serde::{Deserialize, Serialize};
use std::collections::HashSet;
use std::fs::File;
use std::io::{BufReader, Read};
use std::path::PathBuf;
use std::sync::mpsc::{channel, Receiver, Sender, TryRecvError};
use std::thread;
use uuid::Uuid;

const COLLISION_GAP: f32 = 1.0;
const MIN_BLOCK_SIZE: f32 = 50.0;

// --- Image Decoder Module ---

mod image_decoder {

    /// Image format enum
    #[derive(Clone, Copy)]
    pub enum ImageFormat {
        Avif,
        Gif,
        Webp,
    }

    /// Decoded AVIF frame with RGBA pixels
    pub struct AvifFrame {
        pub pixels: Vec<u8>,
        pub width: u32,
        pub height: u32,
        pub duration: f64,
    }

    /// Result of decoding an AVIF file
    pub struct AvifDecodeResult {
        pub frames: Vec<AvifFrame>,
    }

    /// Result of decoding just the first frame (for preview)
    pub struct AvifFirstFrameResult {
        pub frame: AvifFrame,
        pub aspect_ratio: f32,
        pub total_frame_count: usize,
        pub frame_durations: Vec<f64>,
    }

    /// RAII wrapper for avifDecoder to ensure proper cleanup
    struct DecoderGuard {
        decoder: *mut libavif_sys::avifDecoder,
    }

    impl DecoderGuard {
        fn new() -> Option<Self> {
            let decoder = unsafe { libavif_sys::avifDecoderCreate() };
            if decoder.is_null() {
                return None;
            } else {
                // Enable multi-threaded decoding using all available CPU cores
                unsafe {
                    let num_cpus = std::thread::available_parallelism()
                        .map(|p| p.get() as i32)
                        .unwrap_or(4);
                    (*decoder).maxThreads = num_cpus;
                }
                return Some(Self { decoder });
            }
        }
    }

    impl Drop for DecoderGuard {
        fn drop(&mut self) {
            unsafe { libavif_sys::avifDecoderDestroy(self.decoder) };
        }
    }

    /// RAII wrapper for avifRGBImage pixels to ensure proper cleanup
    struct RgbImageGuard {
        rgb: libavif_sys::avifRGBImage,
        allocated: bool,
    }

    impl RgbImageGuard {
        fn new() -> Self {
            Self {
                rgb: unsafe { std::mem::zeroed() },
                allocated: false,
            }
        }

        fn allocate(&mut self, image: *const libavif_sys::avifImage) {
            unsafe {
                libavif_sys::avifRGBImageSetDefaults(&mut self.rgb, image);
                self.rgb.format = libavif_sys::AVIF_RGB_FORMAT_RGBA;
                self.rgb.depth = 8;
                libavif_sys::avifRGBImageAllocatePixels(&mut self.rgb);
                self.allocated = true;
            }
        }

        fn convert_from_yuv(&mut self, image: *const libavif_sys::avifImage) {
            unsafe {
                libavif_sys::avifImageYUVToRGB(image, &mut self.rgb);
            }
        }

        fn extract_pixels(&self) -> Vec<u8> {
            let width = self.rgb.width;
            let height = self.rgb.height;
            let row_bytes = self.rgb.rowBytes;

            let mut packed_pixels = Vec::with_capacity((width * height * 4) as usize);
            unsafe {
                let pixel_slice =
                    std::slice::from_raw_parts(self.rgb.pixels, (row_bytes * height) as usize);
                for y in 0..height {
                    let src_offset = (y * row_bytes) as usize;
                    let src_row = &pixel_slice[src_offset..src_offset + (width * 4) as usize];
                    packed_pixels.extend_from_slice(src_row);
                }
            }
            packed_pixels
        }
    }

    impl Drop for RgbImageGuard {
        fn drop(&mut self) {
            if self.allocated {
                unsafe { libavif_sys::avifRGBImageFreePixels(&mut self.rgb) };
            }
        }
    }

    /// Decoded GIF frame with RGBA pixels
    pub struct GifFrame {
        pub pixels: Vec<u8>,
        pub width: u32,
        pub height: u32,
        pub duration: f64,
    }

    /// Result of decoding a GIF file
    pub struct GifDecodeResult {
        pub frames: Vec<GifFrame>,
    }

    /// Result of decoding just the first frame of GIF (for preview)
    pub struct GifFirstFrameResult {
        pub frame: GifFrame,
        pub aspect_ratio: f32,
        pub total_frame_count: usize,
        pub frame_durations: Vec<f64>,
    }

    /// Decoded WebP frame with RGBA pixels
    pub struct WebpFrame {
        pub pixels: Vec<u8>,
        pub width: u32,
        pub height: u32,
        pub duration: f64,
    }

    /// Result of decoding a WebP file
    pub struct WebpDecodeResult {
        pub frames: Vec<WebpFrame>,
    }

    /// Result of decoding just the first frame of WebP (for preview)
    pub struct WebpFirstFrameResult {
        pub frame: WebpFrame,
        pub aspect_ratio: f32,
        pub total_frame_count: usize,
        pub frame_durations: Vec<f64>,
    }

    /// Decode an AVIF file from bytes, supporting both static and animated images.
    ///
    /// Returns `None` if decoding fails at any step.
    pub fn decode_avif(data: &[u8]) -> Option<AvifDecodeResult> {
        let decoder = DecoderGuard::new()?;

        // Set up memory IO and parse the file
        let result = unsafe {
            libavif_sys::avifDecoderSetIOMemory(decoder.decoder, data.as_ptr(), data.len())
        };
        if result != libavif_sys::AVIF_RESULT_OK {
            return None;
        }

        let result = unsafe { libavif_sys::avifDecoderParse(decoder.decoder) };
        if result != libavif_sys::AVIF_RESULT_OK {
            return None;
        }

        let mut frames = Vec::new();

        // Get the total animation duration and frame count for fallback calculation
        let image_count = unsafe { (*decoder.decoder).imageCount } as usize;
        let total_duration = unsafe { (*decoder.decoder).duration };

        // Calculate fallback duration per frame if individual frame timing is invalid
        let fallback_duration = if image_count > 1 && total_duration > 0.0 {
            total_duration / image_count as f64
        } else {
            0.1 // Default 100ms for animated images with no timing info
        };

        let mut frame_index: u32 = 0;

        // Decode all frames
        while unsafe { libavif_sys::avifDecoderNextImage(decoder.decoder) }
            == libavif_sys::AVIF_RESULT_OK
        {
            let image = unsafe { (*decoder.decoder).image };
            if image.is_null() {
                continue;
            }

            let (width, height) = unsafe { ((*image).width, (*image).height) };

            // Convert YUV to RGBA
            let mut rgb = RgbImageGuard::new();
            rgb.allocate(image);
            rgb.convert_from_yuv(image);

            let pixels = rgb.extract_pixels();

            // Get timing using avifDecoderNthImageTiming for more reliable results
            let duration = unsafe {
                let mut timing: libavif_sys::avifImageTiming = std::mem::zeroed();
                let timing_result = libavif_sys::avifDecoderNthImageTiming(
                    decoder.decoder,
                    frame_index,
                    &mut timing,
                );

                if timing_result == libavif_sys::AVIF_RESULT_OK && timing.duration > 0.0 {
                    timing.duration
                } else {
                    // Fallback: use decoder's imageTiming.duration
                    let img_timing_duration = (*decoder.decoder).imageTiming.duration;
                    if img_timing_duration > 0.0 {
                        img_timing_duration
                    } else if image_count > 1 {
                        // For animated images with no per-frame timing, use calculated fallback
                        fallback_duration
                    } else {
                        // Static image
                        0.0
                    }
                }
            };

            frames.push(AvifFrame {
                pixels,
                width,
                height,
                duration,
            });

            frame_index += 1;
        }

        if frames.is_empty() {
            return None;
        }

        Some(AvifDecodeResult { frames })
    }

    /// Decode only the first frame of an AVIF file (fast preview)
    /// Also extracts metadata about frame count and durations
    pub fn decode_avif_first_frame(data: &[u8]) -> Option<AvifFirstFrameResult> {
        let decoder = DecoderGuard::new()?;

        let result = unsafe {
            libavif_sys::avifDecoderSetIOMemory(decoder.decoder, data.as_ptr(), data.len())
        };
        if result != libavif_sys::AVIF_RESULT_OK {
            return None;
        }

        let result = unsafe { libavif_sys::avifDecoderParse(decoder.decoder) };
        if result != libavif_sys::AVIF_RESULT_OK {
            return None;
        }

        let image_count = unsafe { (*decoder.decoder).imageCount } as usize;
        let total_duration = unsafe { (*decoder.decoder).duration };

        let fallback_duration = if image_count > 1 && total_duration > 0.0 {
            total_duration / image_count as f64
        } else {
            0.1
        };

        // Extract all frame durations (metadata only, no pixel decoding)
        let mut frame_durations = Vec::with_capacity(image_count);
        for i in 0..image_count {
            let duration = unsafe {
                let mut timing: libavif_sys::avifImageTiming = std::mem::zeroed();
                let timing_result =
                    libavif_sys::avifDecoderNthImageTiming(decoder.decoder, i as u32, &mut timing);

                if timing_result == libavif_sys::AVIF_RESULT_OK && timing.duration > 0.0 {
                    timing.duration
                } else if image_count > 1 {
                    fallback_duration
                } else {
                    0.0
                }
            };
            frame_durations.push(duration);
        }

        // Decode only the first frame
        let result = unsafe { libavif_sys::avifDecoderNextImage(decoder.decoder) };
        if result != libavif_sys::AVIF_RESULT_OK {
            return None;
        }

        let image = unsafe { (*decoder.decoder).image };
        if image.is_null() {
            return None;
        }

        let (width, height) = unsafe { ((*image).width, (*image).height) };
        let aspect_ratio = if width > 0 && height > 0 {
            width as f32 / height as f32
        } else {
            1.0
        };

        let mut rgb = RgbImageGuard::new();
        rgb.allocate(image);
        rgb.convert_from_yuv(image);

        let pixels = rgb.extract_pixels();

        Some(AvifFirstFrameResult {
            frame: AvifFrame {
                pixels,
                width,
                height,
                duration: frame_durations.first().copied().unwrap_or(0.1),
            },
            aspect_ratio,
            total_frame_count: image_count,
            frame_durations,
        })
    }

    /// Decode a GIF file from bytes, supporting both static and animated images.
    pub fn decode_gif(data: &[u8]) -> Option<GifDecodeResult> {
        let mut decoder = gif::DecodeOptions::new();
        decoder.set_color_output(gif::ColorOutput::RGBA);
        let mut decoder = decoder.read_info(std::io::Cursor::new(data)).ok()?;

        let mut frames = Vec::new();

        while let Some(frame) = decoder.read_next_frame().ok().flatten() {
            let pixels = frame.buffer.to_vec();
            frames.push(GifFrame {
                pixels,
                width: frame.width as u32,
                height: frame.height as u32,
                duration: frame.delay as f64 / 100.0,
            });
        }

        if frames.is_empty() {
            None
        } else {
            Some(GifDecodeResult { frames })
        }
    }

    /// Decode only the first frame of a GIF file (fast preview)
    pub fn decode_gif_first_frame(data: &[u8]) -> Option<GifFirstFrameResult> {
        let mut decoder = gif::DecodeOptions::new();
        decoder.set_color_output(gif::ColorOutput::RGBA);
        let mut decoder = decoder.read_info(std::io::Cursor::new(data)).ok()?;

        let width = decoder.width() as u32;
        let height = decoder.height() as u32;
        let aspect_ratio = if height > 0 { width as f32 / height as f32 } else { 1.0 };

        let mut frame_durations = Vec::new();
        let mut first_frame_pixels = None;

        while let Some(frame) = decoder.read_next_frame().ok().flatten() {
            frame_durations.push(frame.delay as f64 / 100.0);
            if first_frame_pixels.is_none() {
                first_frame_pixels = Some(frame.buffer.to_vec());
            }
        }

        let total_frame_count = frame_durations.len();

        if let Some(pixels) = first_frame_pixels {
            Some(GifFirstFrameResult {
                frame: GifFrame {
                    pixels,
                    width,
                    height,
                    duration: frame_durations.first().copied().unwrap_or(0.1),
                },
                aspect_ratio,
                total_frame_count,
                frame_durations,
            })
        } else {
            None
        }
    }

    /// Decode a WebP file from bytes, supporting both static and animated images.
    pub fn decode_webp(data: &[u8]) -> Option<WebpDecodeResult> {
        let decoder = webp::AnimDecoder::new(data);
        let anim = decoder.decode().ok()?;

        let mut frames = Vec::new();
        let mut prev_timestamp = 0;
        for frame in &anim {
            let timestamp = frame.get_time_ms();
            let delay_ms = timestamp.saturating_sub(prev_timestamp);
            let duration = if delay_ms > 0 {
                delay_ms as f64 / 1000.0
            } else if anim.has_animation() {
                0.1
            } else {
                0.0
            };
            prev_timestamp = timestamp;

            let img: image::DynamicImage = (&frame).into();
            let buffer = img.to_rgba8();
            let pixels = buffer.as_raw().to_vec();
            frames.push(WebpFrame {
                pixels,
                width: buffer.width(),
                height: buffer.height(),
                duration,
            });
        }

        if frames.is_empty() {
            None
        } else {
            Some(WebpDecodeResult { frames })
        }
    }

    /// Decode only the first frame of a WebP file (fast preview)
    pub fn decode_webp_first_frame(data: &[u8]) -> Option<WebpFirstFrameResult> {
        let decoder = webp::AnimDecoder::new(data);
        let anim = decoder.decode().ok()?;

        if anim.len() == 0 {
            return None;
        }

        let first_frame = anim.get_frame(0)?;
        let width = first_frame.width();
        let height = first_frame.height();
        let aspect_ratio = if height > 0 { width as f32 / height as f32 } else { 1.0 };

        let mut frame_durations = Vec::new();
        let mut prev_timestamp = 0;
        for frame in &anim {
            let timestamp = frame.get_time_ms();
            let delay_ms = timestamp.saturating_sub(prev_timestamp);
            let delay = if delay_ms > 0 {
                delay_ms as f64 / 1000.0
            } else if anim.has_animation() {
                0.1
            } else {
                0.0
            };
            prev_timestamp = timestamp;
            frame_durations.push(delay);
        }

        let img: image::DynamicImage = (&first_frame).into();
        let buffer = img.to_rgba8();
        let pixels = buffer.as_raw().to_vec();

        Some(WebpFirstFrameResult {
            frame: WebpFrame {
                pixels,
                width: width as u32,
                height: height as u32,
                duration: frame_durations.first().copied().unwrap_or(0.1),
            },
            aspect_ratio,
            total_frame_count: anim.len(),
            frame_durations,
        })
    }
}

#[derive(Clone, Copy, PartialEq)]
enum ResizeHandle {
    TopLeft,
    TopRight,
    BottomLeft,
    BottomRight,
}

#[derive(Clone)]
struct InteractionState {
    id: Uuid,
    handle: ResizeHandle,
    initial_mouse_pos: Pos2,
    initial_block_rect: Rect,
}

/// Animation loading state for lazy-loaded animated images
#[derive(Clone)]
enum AnimationState {
    /// Not animated (static image) or fully loaded animation
    Ready,
    /// Animation not yet loaded - shows first frame, waiting for user to click play
    NotLoaded {
        path: String,
        format: image_decoder::ImageFormat,
        total_frame_count: usize,
        frame_durations: Vec<f64>,
    },
    /// Currently loading animation frames in background
    Loading { total_frame_count: usize },
    /// Animation paused due to concurrent limit - can be resumed on click
    Paused {
        total_frame_count: usize,
        frame_durations: Vec<f64>,
        aspect_ratio: f32,
        path: String,
        format: image_decoder::ImageFormat,
    },
}

#[derive(Clone)]
enum BlockContent {
    Text {
        text: String,
    },
    Image {
        frames: Vec<egui::TextureHandle>,
        frame_delays: Vec<f64>, // Seconds
        aspect_ratio: f32,
        playing: bool,
        current_frame_idx: usize,
        last_frame_time: f64,
        counter: i32,
        path: Option<String>,
        /// Animation loading state (for lazy-loaded AVIF animations)
        animation_state: AnimationState,
        /// First frame ColorImage for paused animations
        first_frame: Option<egui::ColorImage>,
        /// Time when animation started playing (for concurrent limit management)
        playing_start_time: Option<f64>,
    },
}

#[derive(Clone)]
struct Block {
    id: Uuid,
    rect: Rect, // World coordinates
    content: BlockContent,
    chained: bool,
    selected: bool,
}

#[derive(Default)]
struct Viewport {
    pan: Vec2,
    zoom: f32,
}

struct CanvasApp {
    viewport: Viewport,
    blocks: Vec<Block>,
    /// State for resizing (Right mouse drag)
    resizing_state: Option<InteractionState>,
    /// UUID of the text block currently being edited
    editing_id: Option<Uuid>,
    /// Request to focus a specific text widget
    focus_request: Option<Uuid>,
    /// Track the last dragged block to resolve collisions only for it
    last_dragged_id: Option<Uuid>,
    /// Timestamp of the last interaction with a chained block
    last_chain_interaction: f64,
    /// Channel for receiving loaded image data from background threads
    image_rx: Receiver<ImageLoadData>,
    /// Sender to clone for background threads
    image_tx: Sender<ImageLoadData>,
    /// Channel for receiving file paths from file dialog
    file_dialog_rx: Receiver<Vec<PathBuf>>,
    /// Sender for file dialog results
    file_dialog_tx: Sender<Vec<PathBuf>>,
    /// Is the counter tool active?
    counter_tool_active: bool,
    /// Show help window
    show_help: bool,
    /// Cache for markdown rendering
    common_mark_cache: CommonMarkCache,
    /// Maximum number of concurrent animations allowed
    max_concurrent_animations: usize,
    /// Current number of playing animations
    current_concurrent_animations: usize,
}

/// Data sent from background image loading thread
#[derive(Clone)]
enum ImageLoadData {
    /// Full image loaded (all frames ready)
    Complete {
        frames: Vec<egui::ColorImage>,
        frame_delays: Vec<f64>,
        aspect_ratio: f32,
        path: Option<String>,
        target_block_id: Option<Uuid>,
    },
    /// AVIF preview - only first frame loaded, animation available on demand
    AvifPreview {
        first_frame: egui::ColorImage,
        frame_durations: Vec<f64>,
        aspect_ratio: f32,
        total_frame_count: usize,
        path: Option<String>,
        target_block_id: Option<Uuid>,
    },
    /// GIF preview - only first frame loaded, animation available on demand
    GifPreview {
        first_frame: egui::ColorImage,
        frame_durations: Vec<f64>,
        aspect_ratio: f32,
        total_frame_count: usize,
        path: Option<String>,
        target_block_id: Option<Uuid>,
    },
    /// WebP preview - only first frame loaded, animation available on demand
    WebpPreview {
        first_frame: egui::ColorImage,
        frame_durations: Vec<f64>,
        aspect_ratio: f32,
        total_frame_count: usize,
        path: Option<String>,
        target_block_id: Option<Uuid>,
    },
    /// Remaining animation frames loaded (after user clicked play)
    AnimationLoaded {
        target_block_id: Uuid,
        frames: Vec<egui::ColorImage>,
        frame_delays: Vec<f64>,
    },
}

// --- Serialization Structs ---

#[derive(Serialize, Deserialize)]
struct Session {
    viewport: ViewportData,
    blocks: Vec<BlockData>,
}

#[derive(Serialize, Deserialize)]
struct ViewportData {
    pan: [f32; 2],
    zoom: f32,
}

#[derive(Serialize, Deserialize)]
struct BlockData {
    id: Uuid,
    rect: [f32; 4], // min_x, min_y, max_x, max_y
    content: BlockContentData,
    chained: bool,
}

#[derive(Serialize, Deserialize)]
enum BlockContentData {
    Text {
        text: String,
    },
    Image {
        path: String,
        counter: i32,
        playing: bool,
    },
}

impl Default for CanvasApp {
    fn default() -> Self {
        let (tx, rx) = channel();
        let (file_tx, file_rx) = channel();
        Self {
            viewport: Viewport {
                pan: Vec2::ZERO,
                zoom: 1.0,
            },
            blocks: Vec::new(),
            resizing_state: None,
            editing_id: None,
            focus_request: None,
            last_dragged_id: None,
            last_chain_interaction: 0.0,
            image_rx: rx,
            image_tx: tx,
            file_dialog_rx: file_rx,
            file_dialog_tx: file_tx,
            counter_tool_active: false,
            show_help: false,
            common_mark_cache: CommonMarkCache::default(),
            max_concurrent_animations: 15,
            current_concurrent_animations: 0,
        }
    }
}

// --- Physics / Collision Helpers ---

impl Block {
    fn resolve_collision(&mut self, others: &[Block]) -> bool {
        let mut moved = false;
        for _ in 0..3 {
            let mut total_push = Vec2::ZERO;
            let my_rect = self.rect.expand(COLLISION_GAP);

            for other in others {
                if self.id == other.id {
                    continue;
                }

                if my_rect.intersects(other.rect) {
                    let intersection = my_rect.intersect(other.rect);
                    let dx = intersection.width();
                    let dy = intersection.height();
                    let center_diff = self.rect.center() - other.rect.center();

                    let push = if dx < dy {
                        Vec2::new(if center_diff.x > 0.0 { dx } else { -dx }, 0.0)
                    } else {
                        Vec2::new(0.0, if center_diff.y > 0.0 { dy } else { -dy })
                    };
                    total_push += push;
                }
            }

            if total_push != Vec2::ZERO {
                self.rect = self.rect.translate(total_push);
                moved = true;
            }
        }
        moved
    }
}
// --- App Implementation ---

impl eframe::App for CanvasApp {
    fn update(&mut self, ctx: &egui::Context, _frame: &mut eframe::Frame) {
        let mut help_toggled = false;

        let time_now = ctx.input(|i| i.time);

        // Poll for file dialog results
        match self.file_dialog_rx.try_recv() {
            Ok(paths) => {
                for path in paths {
                    self.load_image_file(path, ctx.clone(), None);
                }
            }
            Err(TryRecvError::Empty) => {}
            Err(TryRecvError::Disconnected) => {
                // Recreate channel if disconnected
                let (tx, rx) = channel();
                self.file_dialog_tx = tx;
                self.file_dialog_rx = rx;
            }
        }

        // Poll for loaded image data
        while let Ok(data) = self.image_rx.try_recv() {
            match data {
                ImageLoadData::Complete {
                    frames,
                    frame_delays,
                    aspect_ratio,
                    path,
                    target_block_id,
                } => {
                    if frames.is_empty() {
                        continue;
                    }

                    let texture_frames: Vec<_> = frames
                        .iter()
                        .enumerate()
                        .map(|(i, img)| {
                            ctx.load_texture(
                                format!("img-{}-{i}", Uuid::new_v4()),
                                img.clone(),
                                egui::TextureOptions::default(),
                            )
                        })
                        .collect();

                    if let Some(target_id) = target_block_id {
                        if let Some(block) = self.blocks.iter_mut().find(|b| b.id == target_id) {
                            if let BlockContent::Image {
                                frames: f,
                                frame_delays: fd,
                                aspect_ratio: ar,
                                animation_state,
                                ..
                            } = &mut block.content
                            {
                                *f = texture_frames;
                                *fd = frame_delays;
                                *ar = aspect_ratio;
                                *animation_state = AnimationState::Ready;
                            }
                        }
                    } else {
                        let id = Uuid::new_v4();
                        let width = 300.0;
                        let height = width / aspect_ratio;
                        let size = Vec2::new(width, height);
                        let center_world = -self.viewport.pan;
                        let pos = self.find_free_rect(center_world, size);

                        self.blocks.push(Block {
                            id,
                            rect: Rect::from_min_size(pos.to_pos2(), size),
                            content: BlockContent::Image {
                                frames: texture_frames,
                                frame_delays,
                                aspect_ratio,
                                playing: frames.len() > 1,
                                current_frame_idx: 0,
                                last_frame_time: 0.0,
                                counter: 0,
                                path,
                                animation_state: AnimationState::Ready,
                                first_frame: frames.first().cloned(),
                                playing_start_time: None,
                            },
                            chained: false,
                            selected: false,
                        });
                    }
                }
                ImageLoadData::AvifPreview {
                    first_frame,
                    frame_durations,
                    aspect_ratio,
                    total_frame_count,
                    path,
                    target_block_id,
                } => {
                    let texture = ctx.load_texture(
                        format!("avif-preview-{}", Uuid::new_v4()),
                        first_frame.clone(),
                        egui::TextureOptions::default(),
                    );

                    let animation_state = if total_frame_count > 1 {
                        AnimationState::NotLoaded {
                            path: path.clone().unwrap(),
                            format: image_decoder::ImageFormat::Avif,
                            total_frame_count,
                            frame_durations: frame_durations.clone(),
                        }
                    } else {
                        AnimationState::Ready
                    };

                    if let Some(target_id) = target_block_id {
                        if let Some(block) = self.blocks.iter_mut().find(|b| b.id == target_id) {
                             if let BlockContent::Image {
                                 frames,
                                 frame_delays,
                                 aspect_ratio: ar,
                                 animation_state: anim_state,
                                 first_frame: ff,
                                 ..
                             } = &mut block.content
                             {
                                 *frames = vec![texture];
                                 *frame_delays = frame_durations;
                                 *ar = aspect_ratio;
                                 *anim_state = animation_state;
                                 *ff = Some(first_frame);
                             }
                        }
                    } else {
                        let id = Uuid::new_v4();
                        let width = 300.0;
                        let height = width / aspect_ratio;
                        let size = Vec2::new(width, height);
                        let center_world = -self.viewport.pan;
                        let pos = self.find_free_rect(center_world, size);

                        self.blocks.push(Block {
                            id,
                            rect: Rect::from_min_size(pos.to_pos2(), size),
                            content: BlockContent::Image {
                                frames: vec![texture],
                                frame_delays: frame_durations,
                                aspect_ratio,
                                playing: false, // Don't auto-play, wait for user click
                                current_frame_idx: 0,
                                last_frame_time: 0.0,
                                counter: 0,
                                path,
                                animation_state,
                                first_frame: Some(first_frame),
                                playing_start_time: None,
                            },
                            chained: false,
                            selected: false,
                         });
                     }
                 }
                ImageLoadData::GifPreview {
                    first_frame,
                    frame_durations,
                    aspect_ratio,
                    total_frame_count,
                    path,
                    target_block_id,
                } => {
                      let texture = ctx.load_texture(
                          format!("gif-preview-{}", Uuid::new_v4()),
                          first_frame.clone(),
                          egui::TextureOptions::default(),
                      );

                     let animation_state = if total_frame_count > 1 {
                         AnimationState::NotLoaded {
                             path: path.clone().unwrap(),
                             format: image_decoder::ImageFormat::Gif,
                             total_frame_count,
                             frame_durations: frame_durations.clone(),
                         }
                     } else {
                         AnimationState::Ready
                     };

                     if let Some(target_id) = target_block_id {
                         if let Some(block) = self.blocks.iter_mut().find(|b| b.id == target_id) {
                             if let BlockContent::Image {
                                 frames,
                                 frame_delays,
                                 aspect_ratio: ar,
                                 animation_state: anim_state,
                                 ..
                             } = &mut block.content
                             {
                                 *frames = vec![texture];
                                 *frame_delays = frame_durations;
                                 *ar = aspect_ratio;
                                 *anim_state = animation_state;
                             }
                         }
                      } else {
                          let id = Uuid::new_v4();
                          let width = 300.0;
                          let height = width / aspect_ratio;
                          let size = Vec2::new(width, height);
                          let center_world = -self.viewport.pan;
                          let pos = self.find_free_rect(center_world, size);

                          self.blocks.push(Block {
                              id,
                              rect: Rect::from_min_size(pos.to_pos2(), size),
                              content: BlockContent::Image {
                                  frames: vec![texture],
                                  frame_delays: frame_durations,
                                  aspect_ratio,
                                  playing: false,
                                  current_frame_idx: 0,
                                  last_frame_time: 0.0,
                                  counter: 0,
                                  path,
                                  animation_state,
                                  first_frame: Some(first_frame.clone()),
                                  playing_start_time: None,
                              },
                              chained: false,
                              selected: false,
                          });
                      }
                  }
                 ImageLoadData::WebpPreview {
                    first_frame,
                    frame_durations,
                    aspect_ratio,
                    total_frame_count,
                    path,
                    target_block_id,
                } => {
                      let texture = ctx.load_texture(
                          format!("webp-preview-{}", Uuid::new_v4()),
                          first_frame.clone(),
                          egui::TextureOptions::default(),
                      );

                     let animation_state = if total_frame_count > 1 {
                         AnimationState::NotLoaded {
                             path: path.clone().unwrap(),
                             format: image_decoder::ImageFormat::Webp,
                             total_frame_count,
                             frame_durations: frame_durations.clone(),
                         }
                     } else {
                         AnimationState::Ready
                     };

                     if let Some(target_id) = target_block_id {
                         if let Some(block) = self.blocks.iter_mut().find(|b| b.id == target_id) {
                             if let BlockContent::Image {
                                 frames,
                                 frame_delays,
                                 aspect_ratio: ar,
                                 animation_state: anim_state,
                                 ..
                             } = &mut block.content
                             {
                                 *frames = vec![texture];
                                 *frame_delays = frame_durations;
                                 *ar = aspect_ratio;
                                 *anim_state = animation_state;
                             }
                         }
                      } else {
                          let id = Uuid::new_v4();
                          let width = 300.0;
                          let height = width / aspect_ratio;
                          let size = Vec2::new(width, height);
                          let center_world = -self.viewport.pan;
                          let pos = self.find_free_rect(center_world, size);

                          self.blocks.push(Block {
                              id,
                              rect: Rect::from_min_size(pos.to_pos2(), size),
                              content: BlockContent::Image {
                                  frames: vec![texture],
                                  frame_delays: frame_durations,
                                  aspect_ratio,
                                  playing: false,
                                  current_frame_idx: 0,
                                  last_frame_time: 0.0,
                                  counter: 0,
                                  path,
                                  animation_state,
                                  first_frame: Some(first_frame.clone()),
                                  playing_start_time: None,
                              },
                              chained: false,
                              selected: false,
                          });
                      }
                  }
                  ImageLoadData::AnimationLoaded {
                    target_block_id,
                    frames,
                    frame_delays,
                } => {
                    if let Some(block) = self.blocks.iter_mut().find(|b| b.id == target_block_id) {
                        if let BlockContent::Image {
                            frames: existing_frames,
                            frame_delays: existing_delays,
                            animation_state,
                            playing,
                            last_frame_time,
                            ..
                        } = &mut block.content
                        {
                            // Convert all frames to textures
                            let texture_frames: Vec<_> = frames
                                .iter()
                                .enumerate()
                                .map(|(i, img)| {
                                    ctx.load_texture(
                                        format!("avif-anim-{target_block_id}-{i}"),
                                        img.clone(),
                                        egui::TextureOptions::default(),
                                    )
                                })
                                .collect();

                            *existing_frames = texture_frames;
                            *existing_delays = frame_delays;
                            *animation_state = AnimationState::Ready;
                            *playing = true;
                            *last_frame_time = time_now;
                        }
                    }
                }
            }
        }

        if !self.blocks.is_empty() {
            ctx.request_repaint();
        }

        // 1. Update Animation State (restored sophisticated timing)
        let time_now = ctx.input(|i| i.time);
        for block in &mut self.blocks {
            if let BlockContent::Image {
                frames,
                frame_delays,
                playing,
                current_frame_idx,
                last_frame_time,
                ..
            } = &mut block.content
            {
                if *playing && frames.len() > 1 {
                    // Skip frames if we've fallen behind to maintain correct animation speed
                    let mut elapsed = time_now - *last_frame_time;
                    while elapsed > 0.0 {
                        let delay = frame_delays.get(*current_frame_idx).copied().unwrap_or(0.1);
                        if elapsed >= delay {
                            elapsed -= delay;
                            *current_frame_idx = (*current_frame_idx + 1) % frames.len();
                        } else {
                            break;
                        }
                    }
                    // Update last_frame_time, accounting for partial frame time remaining
                    *last_frame_time = time_now - elapsed;
                }
            }
        }

        // Update concurrent animation count
        self.current_concurrent_animations = self.blocks.iter().filter(|b| {
            if let BlockContent::Image { playing, .. } = &b.content {
                *playing
            } else {
                false
            }
        }).count();

        // 2. Global Inputs
        let input = ctx.input(|i| i.clone());
        if input.raw_scroll_delta.y.abs() > 0.0 {
            let factor = 1.0 + input.raw_scroll_delta.y * 0.001;
            let old_zoom = self.viewport.zoom;
            self.viewport.zoom = (self.viewport.zoom * factor).clamp(0.1, 5.0);

            if let Some(mouse_pos) = input.pointer.hover_pos() {
                let screen_center = ctx.screen_rect().center().to_vec2();
                let mouse_offset = mouse_pos.to_vec2() - screen_center;
                let world_point_under_mouse = (mouse_offset / old_zoom) - self.viewport.pan;
                self.viewport.pan = (mouse_offset / self.viewport.zoom) - world_point_under_mouse;
            }
        }

        if input.pointer.middle_down()
            || (input.key_down(egui::Key::Space) && input.pointer.primary_down())
        {
            self.viewport.pan += input.pointer.delta() / self.viewport.zoom;
        }

        // 3. Toolbar
        egui::TopBottomPanel::top("toolbar")
            .frame(
                egui::Frame::default()
                    .fill(Color32::from_rgb(30, 30, 30))
                    .inner_margin(0.0)
                    .outer_margin(0.0),
            )
            .show(ctx, |ui| {
                ui.horizontal(|ui| {
                    ui.add_space(8.0); // Add gap from window edge
                    if ui
                        .add(
                            egui::Button::new(RichText::new("üíæ").size(24.0))
                                .min_size(Vec2::new(32.0, 32.0))
                                .frame(false),
                        )
                        .on_hover_text("Save Session")
                        .clicked()
                    {
                        self.save_session();
                    }
                    if ui
                        .add(
                            egui::Button::new(RichText::new("üìÇ").size(24.0))
                                .min_size(Vec2::new(32.0, 32.0))
                                .frame(false),
                        )
                        .on_hover_text("Load Session")
                        .clicked()
                    {
                        self.load_session();
                    }

                    if ui
                        .add(
                            egui::Button::new(RichText::new("üî§").size(24.0))
                                .min_size(Vec2::new(32.0, 32.0))
                                .frame(false),
                        )
                        .on_hover_text("Add Text")
                        .clicked()
                    {
                        self.spawn_text_block(ui.ctx());
                    }
                    if ui
                        .add(
                            egui::Button::new(RichText::new("üñº").size(24.0))
                                .min_size(Vec2::new(32.0, 32.0))
                                .frame(false),
                        )
                        .on_hover_text("Add Image")
                        .clicked()
                    {
                        self.spawn_image_block(ui.ctx());
                    }

                    let mut btn = egui::Button::new(RichText::new("üî¢").size(24.0))
                        .min_size(Vec2::new(32.0, 32.0))
                        .frame(false);
                    if self.counter_tool_active {
                        btn = btn.fill(Color32::LIGHT_GREEN);
                    }
                    if ui.add(btn).on_hover_text("Counter Tool").clicked() {
                        self.counter_tool_active = !self.counter_tool_active;
                    }

                    if ui
                        .add(
                            egui::Button::new(RichText::new("üîÑ").size(24.0))
                                .min_size(Vec2::new(32.0, 32.0))
                                .frame(false),
                        )
                        .on_hover_text("Reset All Counters")
                        .clicked()
                    {
                        self.reset_all_counters();
                    }

                    if ui
                        .add(
                            egui::Button::new(RichText::new("‚ùì").size(24.0))
                                .min_size(Vec2::new(32.0, 32.0))
                                .frame(false),
                        )
                        .on_hover_text("Help")
                        .clicked()
                    {
                        self.show_help = !self.show_help;
                        help_toggled = true;
                    }
                });
            });

        // 4. Main Canvas
        egui::CentralPanel::default().show(ctx, |ui| {
            ui.painter()
                .rect_filled(ui.max_rect(), 0.0, Color32::from_rgb(30, 30, 30));
            self.process_canvas(ui);
        });

        let mut help_layer_id = None;
        if self.show_help {
            let mut open = true;
            egui::Window::new("Help")
                .open(&mut open)
                .collapsible(false)
                .show(ctx, |ui| {
                    help_layer_id = Some(ui.layer_id());

                    // Increase text sizes by 1.5x
                    let mut style = egui::Style::default();
                    for (_text_style, font_id) in style.text_styles.iter_mut() {
                        font_id.size *= 1.5;
                    }
                    ui.set_style(style);

                    ui.heading("Controls");
                    ui.label("‚Ä¢ ‚úã Pan: Middle Mouse Drag OR ‚å®Ô∏è Space + Left Mouse Drag");
                    ui.label("‚Ä¢ üîç Zoom: Mouse Wheel");
                    ui.label("‚Ä¢ ‚ú• Move Block: Left Mouse Drag");
                    ui.label("‚Ä¢ ‚ÜòÔ∏è Resize Block: Right Mouse Drag (corners)");
                    ui.label("‚Ä¢ üìù Edit Text: Double Click");
                    ui.label("‚Ä¢ ‚èØÔ∏è Toggle GIF: Click");
                    ui.label("‚Ä¢ ‚ùå Delete Block: Click 'x' handle");
                    ui.label("‚Ä¢ üîó Chain Block: Click 'o' handle (moves together)");
                    ui.separator();
                    ui.heading("Tools");
                    ui.label("‚Ä¢ üíæ Save: Save current session to JSON");
                    ui.label("‚Ä¢ üìÇ Load: Load session from JSON");
                    ui.label("‚Ä¢ üî§ Text: Add new markdown text block");
                    ui.label("‚Ä¢ üñº Image: Add image (PNG, JPG, GIF, AVIF, WEBP)");
                    ui.label("‚Ä¢ üî¢ Counter: Click image to count, Right-click to decrement");
                    ui.label("‚Ä¢ üîÑ Reset: Reset all image counters to zero");
                });
            if !open {
                self.show_help = false;
            }
        }

        if self.show_help && !help_toggled && ctx.input(|i| i.pointer.any_click()) {
            if let Some(pos) = ctx.input(|i| i.pointer.hover_pos()) {
                if let Some(layer_id) = ctx.layer_id_at(pos) {
                    if let Some(help_id) = help_layer_id {
                        if layer_id != help_id {
                            self.show_help = false;
                        }
                    }
                } else {
                    self.show_help = false;
                }
            }
        }
    }
}

impl CanvasApp {
    fn process_canvas(&mut self, ui: &mut egui::Ui) {
        let screen_rect = ui.max_rect();
        let screen_center = screen_rect.center().to_vec2();
        let zoom = self.viewport.zoom;
        let pan = self.viewport.pan;

        let mouse_pos = ui.input(|i| i.pointer.hover_pos());
        let secondary_down = ui.input(|i| i.pointer.secondary_down());
        let secondary_pressed =
            ui.input(|i| i.pointer.button_pressed(egui::PointerButton::Secondary));
    let secondary_released =
        ui.input(|i| i.pointer.button_released(egui::PointerButton::Secondary));

    let time_now = ui.input(|i| i.time);

        // --- Resize Logic ---
        if secondary_pressed && !self.counter_tool_active {
            if let Some(m_pos) = mouse_pos {
                let world_mouse = (m_pos.to_vec2() - screen_center) / zoom - pan;
                if let Some(block) = self
                    .blocks
                    .iter()
                    .rev()
                    .find(|b| b.rect.contains(world_mouse.to_pos2()))
                {
                    let center = block.rect.center();
                    let handle = match (world_mouse.x < center.x, world_mouse.y < center.y) {
                        (true, true) => ResizeHandle::TopLeft,
                        (false, true) => ResizeHandle::TopRight,
                        (true, false) => ResizeHandle::BottomLeft,
                        (false, false) => ResizeHandle::BottomRight,
                    };
                    self.resizing_state = Some(InteractionState {
                        id: block.id,
                        handle,
                        initial_mouse_pos: m_pos,
                        initial_block_rect: block.rect,
                    });
                    self.last_dragged_id = Some(block.id);
                }
            }
        }

        if secondary_released {
            self.resizing_state = None;
        }

        if let Some(state) = &self.resizing_state {
            if let Some(curr_mouse_pos) = mouse_pos {
                if let Some(idx) = self.blocks.iter().position(|b| b.id == state.id) {
                    let delta_screen = curr_mouse_pos - state.initial_mouse_pos;
                    let delta_world = delta_screen / zoom;
                    let mut new_rect = state.initial_block_rect;
                    let min_size = MIN_BLOCK_SIZE;

                    match state.handle {
                        ResizeHandle::BottomRight => {
                            new_rect.max.x += delta_world.x;
                            new_rect.max.y += delta_world.y;
                        }
                        ResizeHandle::BottomLeft => {
                            new_rect.min.x += delta_world.x;
                            new_rect.max.y += delta_world.y;
                        }
                        ResizeHandle::TopRight => {
                            new_rect.max.x += delta_world.x;
                            new_rect.min.y += delta_world.y;
                        }
                        ResizeHandle::TopLeft => {
                            new_rect.min.x += delta_world.x;
                            new_rect.min.y += delta_world.y;
                        }
                    }

                    if new_rect.width() < min_size {
                        if state.handle == ResizeHandle::TopLeft
                            || state.handle == ResizeHandle::BottomLeft
                        {
                            new_rect.min.x = new_rect.max.x - min_size;
                        } else {
                            new_rect.max.x = new_rect.min.x + min_size;
                        }
                    }
                    if new_rect.height() < min_size {
                        if state.handle == ResizeHandle::TopLeft
                            || state.handle == ResizeHandle::TopRight
                        {
                            new_rect.min.y = new_rect.max.y - min_size;
                        } else {
                            new_rect.max.y = new_rect.min.y + min_size;
                        }
                    }

                    if let BlockContent::Image { aspect_ratio, .. } = self.blocks[idx].content {
                        let w = new_rect.width();
                        new_rect.set_height(w / aspect_ratio);
                    }

// Apply the new rectangle to the primary block
                    self.blocks[idx].rect = new_rect;

                    // Handle chained blocks group resizing
                    if self.blocks[idx].chained {
                        // Find the maximum height among all chained blocks to maintain uniform height
                        let max_height = new_rect.height();
                        let chained_count = self.blocks.iter().filter(|b| b.chained).count();
                        
                        // Apply the same resizing to all other chained blocks
                        // but maintain uniform height across all chained blocks
                        if chained_count > 1 {
                            for i in 0..self.blocks.len() {
                                if self.blocks[i].chained {
                                    // For chained blocks, maintain uniform height but preserve aspect ratios
                                    let aspect_ratio = if let BlockContent::Image { aspect_ratio, .. } = self.blocks[i].content {
                                        aspect_ratio
                                    } else {
                                        1.0
                                    };
                                    
                                    // Maintain uniform height for all chained blocks
                                    let new_width = (max_height * aspect_ratio).max(MIN_BLOCK_SIZE);
                                    let center = self.blocks[i].rect.center();
                                    self.blocks[i].rect = Rect::from_center_size(
                                        center,
                                        Vec2::new(new_width, max_height),
                                    );
                                }
                            }
                        }
                    }
                }
            }
        }

        // --- Render & Interaction ---
        let mut ids_to_delete = HashSet::new();
        let mut interact_captured = false;
        let mut pending_move = None;
        let mut animation_load_requests = Vec::new(); // Collect animation load requests

        for i in 0..self.blocks.len() {
            let b_id = self.blocks[i].id;
            let b_rect = self.blocks[i].rect;
            let b_selected = self.blocks[i].selected;
            let b_chained = self.blocks[i].chained;
            let is_editing = self.editing_id == Some(b_id);

            let screen_pos_min = screen_center + (b_rect.min.to_vec2() + pan) * zoom;
            let screen_size = b_rect.size() * zoom;
            let screen_rect = Rect::from_min_size(screen_pos_min.to_pos2(), screen_size);

            if !screen_rect.intersects(screen_rect) {
                continue;
            }

            let border_color = if b_selected {
                Color32::YELLOW
            } else if b_chained {
                Color32::GREEN
            } else {
                Color32::BLACK
            };
            let bg_color = Color32::from_rgb(240, 240, 240);

            ui.painter().rect_filled(screen_rect, 5.0, bg_color);
            ui.painter()
                .rect_stroke(screen_rect, 5.0, Stroke::new(2.0, border_color));

            let interact_id = ui.make_persistent_id(b_id);
            let sense = if is_editing {
                egui::Sense::hover()
            } else if self.counter_tool_active {
                egui::Sense::click()
            } else {
                egui::Sense::click_and_drag()
            };
            let response = ui.interact(screen_rect, interact_id, sense);

            if response.hovered() || response.dragged() {
                interact_captured = true;
            }

            let btn_size = 16.0 * zoom;
            let padding = 4.0 * zoom;
            let top_right = screen_rect.right_top();
            let close_rect = Rect::from_center_size(
                top_right + Vec2::new(-btn_size / 2.0 - padding, btn_size / 2.0 + padding),
                Vec2::splat(btn_size),
            );
            let chain_rect = Rect::from_center_size(
                close_rect.center() - Vec2::new(btn_size + padding, 0.0),
                Vec2::splat(btn_size),
            );

            let close_hovered = mouse_pos.is_some_and(|p| close_rect.contains(p));
            let chain_hovered = mouse_pos.is_some_and(|p| chain_rect.contains(p));

            if response.dragged() && !secondary_down && !ui.input(|i| i.pointer.middle_down()) {
                let delta = response.drag_delta() / zoom;
                pending_move = Some((i, delta));
                self.last_dragged_id = Some(b_id);
            }

            if is_editing {
                let mut child_ui = ui.new_child(
                    egui::UiBuilder::new()
                        .max_rect(screen_rect.shrink(4.0))
                        .layout(egui::Layout::left_to_right(egui::Align::Min)),
                );
                if let Some(text_mut) = self.blocks[i].content.as_text_mut() {
                    let output = egui::TextEdit::multiline(text_mut)
                        .font(egui::FontId::proportional(16.0 * zoom))
                        .frame(false)
                        .desired_width(f32::INFINITY)
                        .show(&mut child_ui);
                    if self.focus_request == Some(b_id) {
                        output.response.request_focus();
                        self.focus_request = None;
                    }
                    if ui.input(|inp| inp.key_pressed(egui::Key::Escape)) {
                        self.editing_id = None;
                    }
                }
            } else {
                match &mut self.blocks[i].content {
                    BlockContent::Text { text } => {
                        let mut child_ui = ui.new_child(
                            egui::UiBuilder::new()
                                .max_rect(screen_rect.shrink(5.0 * zoom))
                                .layout(egui::Layout::left_to_right(egui::Align::Min)),
                        );
                        for (_text_style, font_id) in child_ui.style_mut().text_styles.iter_mut() {
                            font_id.size *= zoom;
                        }
                        CommonMarkViewer::new().show(
                            &mut child_ui,
                            &mut self.common_mark_cache,
                            text,
                        );
                        if response.double_clicked() && !close_hovered && !chain_hovered {
                            self.editing_id = Some(b_id);
                            self.focus_request = Some(b_id);
                        }
                    }
                    BlockContent::Image {
                        frames,
                        current_frame_idx,
                        playing,
                        counter,
                        animation_state,
                        playing_start_time,
                        frame_delays,
                        aspect_ratio,
                        path,
                        ..
                    } => {
                        if let Some(tex) = frames.get(*current_frame_idx) {
                            ui.painter().image(
                                tex.id(),
                                screen_rect,
                                Rect::from_min_max(Pos2::ZERO, Pos2::new(1.0, 1.0)),
                                Color32::WHITE,
                            );
                        }

                        // Show loading indicator for animation frames
                        if let AnimationState::Loading { total_frame_count } = animation_state {
                            let loading_text =
                                format!("Loading {}/{}", frames.len(), total_frame_count);
                            ui.painter().text(
                                screen_rect.center(),
                                Align2::CENTER_CENTER,
                                loading_text,
                                egui::FontId::proportional(16.0 * zoom),
                                Color32::WHITE,
                            );
                        }

                        if *counter > 0 {
                            let circle_radius = 15.0 * zoom;
                            let circle_center = screen_rect.min
                                + Vec2::new(circle_radius + 5.0, circle_radius + 5.0);
                            ui.painter().circle_filled(
                                circle_center,
                                circle_radius,
                                Color32::GREEN,
                            );
                            ui.painter().text(
                                circle_center,
                                Align2::CENTER_CENTER,
                                counter.to_string(),
                                egui::FontId::proportional(20.0 * zoom),
                                Color32::BLACK,
                            );
                        }

                        if self.counter_tool_active {
                            if response.clicked() {
                                *counter += 1;
                            } else if response.secondary_clicked() {
                                *counter = (*counter - 1).max(0);
                            }
                        } else if response.clicked() && !close_hovered && !chain_hovered {
                            // Handle animation state transitions
                            match animation_state {
                                AnimationState::NotLoaded { .. } => {
                                    // Collect request to start loading animation frames
                                    animation_load_requests.push((b_id,));
                                }
                                AnimationState::Paused { .. } => {
                                    *playing = true;
                                    *animation_state = AnimationState::Ready;
                                    *playing_start_time = Some(time_now);
                                    self.current_concurrent_animations += 1;
                                    if self.current_concurrent_animations > self.max_concurrent_animations {
                                        self.pause_oldest_animation();
                                    }
                                }
                                AnimationState::Ready => {
                                    if *playing {
                                        *playing = false;
                                        self.current_concurrent_animations -= 1;
                                    } else {
                                        *playing = true;
                                        *playing_start_time = Some(time_now);
                                        self.current_concurrent_animations += 1;
                                        if self.current_concurrent_animations > self.max_concurrent_animations {
                                            self.pause_oldest_animation();
                                        }
                                    }
                                }
                                AnimationState::Loading { .. } => {
                                    // Do nothing, wait for loading
                                }
                            }
                        }
                    }
                }
            }

            if response.hovered() || response.dragged() || b_chained {
                ui.painter().circle_filled(
                    close_rect.center(),
                    btn_size / 2.0,
                    if close_hovered {
                        Color32::from_rgb(255, 100, 100)
                    } else {
                        Color32::RED
                    },
                );
                ui.painter().text(
                    close_rect.center(),
                    Align2::CENTER_CENTER,
                    "x",
                    egui::FontId::monospace(12.0 * zoom),
                    Color32::WHITE,
                );
                ui.painter().circle_filled(
                    chain_rect.center(),
                    btn_size / 2.0,
                    if b_chained {
                        Color32::GREEN
                    } else if chain_hovered {
                        Color32::LIGHT_GRAY
                    } else {
                        Color32::GRAY
                    },
                );
                ui.painter().text(
                    chain_rect.center(),
                    Align2::CENTER_CENTER,
                    "o",
                    egui::FontId::monospace(12.0 * zoom),
                    Color32::WHITE,
                );

                if response.clicked() {
                    if close_hovered {
                        ids_to_delete.insert(b_id);
                    } else if chain_hovered {
                        self.blocks[i].chained = !self.blocks[i].chained;
                        self.last_chain_interaction = ui.input(|i| i.time);
                    }
                }
            }
        }

        if let Some((idx, delta)) = pending_move {
            let mut moved_indices = vec![idx];
            if self.blocks[idx].chained {
                self.last_chain_interaction = ui.input(|i| i.time);
                for (i, b) in self.blocks.iter().enumerate() {
                    if i != idx && b.chained {
                        moved_indices.push(i);
                    }
                }
            }
            for &i in &moved_indices {
                self.blocks[i].rect = self.blocks[i].rect.translate(delta);
            }
        }

        if ui.input(|i| {
            i.pointer.button_released(egui::PointerButton::Primary)
                || i.pointer.button_released(egui::PointerButton::Secondary)
        }) {
            if let Some(dragged_id) = self.last_dragged_id {
                if let Some(idx) = self.blocks.iter().position(|b| b.id == dragged_id) {
                    let others = self.blocks.clone();
                    self.blocks[idx].resolve_collision(&others);
                    if self.blocks[idx].chained {
                        for i in 0..self.blocks.len() {
                            if self.blocks[i].chained && i != idx {
                                self.blocks[i].resolve_collision(&others);
                            }
                        }
                    }
                }
            }
        }
        // Process animation load requests
        for (block_id,) in animation_load_requests {
            if let Some(block) = self.blocks.iter_mut().find(|b| b.id == block_id) {
                if let BlockContent::Image {
                    animation_state, ..
                } = &mut block.content
                {
                    let not_loaded = std::mem::replace(animation_state, AnimationState::Ready);
                    if let AnimationState::NotLoaded {
                        path,
                        format,
                        total_frame_count,
                        frame_durations,
                    } = not_loaded
                    {
                        let path = path;
                        let frame_durations = frame_durations;
                        let tx = self.image_tx.clone();

                        // Update state to loading
                        *animation_state = AnimationState::Loading {
                            total_frame_count,
                        };

                        thread::spawn(move || {
                            // Read the file again to decode
                            let frames = if let Ok(mut file) = std::fs::File::open(&path) {
                                let mut buffer = Vec::new();
                                if file.read_to_end(&mut buffer).is_ok() {
                                    match format {
                                        image_decoder::ImageFormat::Avif => {
                                            if let Some(result) = image_decoder::decode_avif(&buffer) {
                                                result.frames.into_iter().map(|frame| {
                                                    let size = [frame.width as usize, frame.height as usize];
                                                    egui::ColorImage::from_rgba_unmultiplied(size, &frame.pixels)
                                                }).collect()
                                            } else {
                                                Vec::new()
                                            }
                                        }
                                        image_decoder::ImageFormat::Gif => {
                                            if let Some(result) = image_decoder::decode_gif(&buffer) {
                                                result.frames.into_iter().map(|frame| {
                                                    let size = [frame.width as usize, frame.height as usize];
                                                    egui::ColorImage::from_rgba_unmultiplied(size, &frame.pixels)
                                                }).collect()
                                            } else {
                                                Vec::new()
                                            }
                                        }
                                        image_decoder::ImageFormat::Webp => {
                                            if let Some(result) = image_decoder::decode_webp(&buffer) {
                                                result.frames.into_iter().map(|frame| {
                                                    let size = [frame.width as usize, frame.height as usize];
                                                    egui::ColorImage::from_rgba_unmultiplied(size, &frame.pixels)
                                                }).collect()
                                            } else {
                                                Vec::new()
                                            }
                                        }
                                    }
                                } else {
                                    Vec::new()
                                }
                            } else {
                                Vec::new()
                            };

                            if !frames.is_empty() {
                                let _ = tx.send(ImageLoadData::AnimationLoaded {
                                    target_block_id: block_id,
                                    frames,
                                    frame_delays: frame_durations,
                                });
                            }
                        });
                    } else {
                        *animation_state = not_loaded;
                    }
                }
            }
        }

        self.blocks.retain(|b| !ids_to_delete.contains(&b.id));

        if ui.input(|i| i.pointer.any_click()) && !interact_captured && !secondary_down {
            self.editing_id = None;
            for b in &mut self.blocks {
                b.selected = false;
            }
        }

        let time_now = ui.input(|i| i.time);
        if self.blocks.iter().any(|b| b.chained) {
            if time_now - self.last_chain_interaction > 10.0 {
                for b in &mut self.blocks {
                    b.chained = false;
                }
            } else {
                ui.ctx()
                    .request_repaint_after(std::time::Duration::from_secs_f64(
                        (10.0 - (time_now - self.last_chain_interaction)).max(0.0),
                    ));
            }
        }
    }

    fn spawn_text_block(&mut self, _ctx: &egui::Context) {
        let center_world = -self.viewport.pan;
        let size = Vec2::new(200.0, 100.0);
        let pos = self.find_free_rect(center_world, size);
        self.blocks.push(Block {
            id: Uuid::new_v4(),
            rect: Rect::from_min_size(pos.to_pos2(), size),
            content: BlockContent::Text {
                text: "Double click to edit...".to_string(),
            },
            chained: false,
            selected: false,
        });
    }

    fn spawn_image_block(&mut self, _ctx: &egui::Context) {
        let tx = self.file_dialog_tx.clone();
        thread::spawn(move || {
            if let Some(paths) = FileDialog::new()
                .add_filter("Image", &["png", "jpg", "jpeg", "gif", "avif", "webp"])
                .pick_files()
            {
                let _ = tx.send(paths);
            }
        });
    }

    fn load_image_file(&self, path: PathBuf, _ctx: egui::Context, target_block_id: Option<Uuid>) {
        let tx = self.image_tx.clone();
        let path_str = path.to_string_lossy().to_string();

        thread::spawn(move || {
            let is_gif = path
                .extension()
                .is_some_and(|e| e.to_string_lossy().to_lowercase() == "gif");
            let is_avif = path
                .extension()
                .is_some_and(|e| e.to_string_lossy().to_lowercase() == "avif");
            let is_webp = path
                .extension()
                .is_some_and(|e| e.to_string_lossy().to_lowercase() == "webp");
            let mut frames_data = vec![];
            let mut delays = vec![];
            let mut aspect = 1.0;

            if is_gif {
                match File::open(&path) {
                    Ok(mut file) => {
                        let mut buffer = Vec::new();
                        if file.read_to_end(&mut buffer).is_ok() {
                            if let Some(preview) = image_decoder::decode_gif_first_frame(&buffer) {
                                if preview.total_frame_count > 1 {
                                    // Animated GIF - send preview only
                                    let first_frame = egui::ColorImage::from_rgba_unmultiplied(
                                        [preview.frame.width as usize, preview.frame.height as usize],
                                        &preview.frame.pixels,
                                    );
                                    let _ = tx.send(ImageLoadData::GifPreview {
                                        first_frame,
                                        frame_durations: preview.frame_durations,
                                        aspect_ratio: preview.aspect_ratio,
                                        total_frame_count: preview.total_frame_count,
                                        path: Some(path_str),
                                        target_block_id,
                                    });
                                    return;
                                } else {
                                    // Static GIF - just one frame
                                    let size = [preview.frame.width as usize, preview.frame.height as usize];
                                    frames_data.push(egui::ColorImage::from_rgba_unmultiplied(
                                        size,
                                        &preview.frame.pixels,
                                    ));
                                    delays.push(preview.frame.duration);
                                    aspect = preview.aspect_ratio;
                                }
                            }
                        }
                    }
                    Err(e) => eprintln!("GIF open error: {e}"),
                }
            } else if is_avif {
                match File::open(&path) {
                    Ok(mut file) => {
                        let mut buffer = Vec::new();
                        if file.read_to_end(&mut buffer).is_ok() {
                            // For animated AVIFs (>1 frame), use lazy loading
                            // Load only first frame immediately, rest on demand
                            if let Some(preview) = image_decoder::decode_avif_first_frame(&buffer) {
                                if preview.total_frame_count > 1 {
                                    // Animated AVIF - send preview only
                                    let first_frame = egui::ColorImage::from_rgba_unmultiplied(
                                        [
                                            preview.frame.width as usize,
                                            preview.frame.height as usize,
                                        ],
                                        &preview.frame.pixels,
                                    );
                                     let _ = tx.send(ImageLoadData::AvifPreview {
                                         first_frame,
                                         frame_durations: preview.frame_durations,
                                         aspect_ratio: preview.aspect_ratio,
                                         total_frame_count: preview.total_frame_count,
                                         path: Some(path_str),
                                         target_block_id,
                                     });
                                    return;
                                } else {
                                    // Static AVIF - just one frame
                                    let size = [
                                        preview.frame.width as usize,
                                        preview.frame.height as usize,
                                    ];
                                    frames_data.push(egui::ColorImage::from_rgba_unmultiplied(
                                        size,
                                        &preview.frame.pixels,
                                    ));
                                    delays.push(preview.frame.duration);
                                    aspect = preview.aspect_ratio;
                                }
                            }
                        }
                    }
                    Err(e) => eprintln!("AVIF open error: {e}"),
                }
            } else if is_webp {
                if let Ok(mut file) = File::open(&path) {
                    let mut buffer = Vec::new();
                    if file.read_to_end(&mut buffer).is_ok() {
                        if let Some(preview) = image_decoder::decode_webp_first_frame(&buffer) {
                            if preview.total_frame_count > 1 {
                                // Animated WebP - send preview only
                                let first_frame = egui::ColorImage::from_rgba_unmultiplied(
                                    [preview.frame.width as usize, preview.frame.height as usize],
                                    &preview.frame.pixels,
                                );
                                let _ = tx.send(ImageLoadData::WebpPreview {
                                    first_frame,
                                    frame_durations: preview.frame_durations,
                                    aspect_ratio: preview.aspect_ratio,
                                    total_frame_count: preview.total_frame_count,
                                    path: Some(path_str),
                                    target_block_id,
                                });
                                return;
                            } else {
                                // Static WebP - just one frame
                                let size = [preview.frame.width as usize, preview.frame.height as usize];
                                frames_data.push(egui::ColorImage::from_rgba_unmultiplied(
                                    size,
                                    &preview.frame.pixels,
                                ));
                                delays.push(preview.frame.duration);
                                aspect = preview.aspect_ratio;
                            }
                        }
                    }
                }
            } else if let Ok(img) = image::open(&path) {
                let buffer = img.to_rgba8();
                let size = [buffer.width() as usize, buffer.height() as usize];
                if size[0] > 0 && size[1] > 0 {
                    aspect = size[0] as f32 / size[1] as f32;
                    frames_data.push(egui::ColorImage::from_rgba_unmultiplied(
                        size,
                        buffer.as_raw(),
                    ));
                    delays.push(0.0);
                }
            }

            if !frames_data.is_empty() {
                let _ = tx.send(ImageLoadData::Complete {
                    frames: frames_data,
                    frame_delays: delays,
                    aspect_ratio: aspect,
                    path: Some(path_str),
                    target_block_id,
                });
            }
        });
    }

    fn find_free_rect(&self, start_pos: Vec2, size: Vec2) -> Vec2 {
        let spacing = 20.0;
        let step_x = size.x + spacing;
        let step_y = size.y + spacing;

        // Try positions in a spiral pattern around start_pos
        // First try the start position itself
        let candidate = Rect::from_min_size(start_pos.to_pos2(), size);
        if !self.blocks.iter().any(|b| b.rect.intersects(candidate)) {
            return start_pos;
        }

        // Then try in expanding rings around start position
        for ring in 1..20 {
            let ring_f = ring as f32;
            // Try positions along each ring (right, down, left, up pattern)
            for i in 0..(ring * 8) {
                let (dx, dy) = match i / (ring * 2) {
                    0 => (i % (ring * 2), 0),                     // top edge, going right
                    1 => (ring * 2, i % (ring * 2)),              // right edge, going down
                    2 => (ring * 2 - (i % (ring * 2)), ring * 2), // bottom edge, going left
                    _ => (0, ring * 2 - (i % (ring * 2))),        // left edge, going up
                };

                let offset =
                    Vec2::new((dx as f32 - ring_f) * step_x, (dy as f32 - ring_f) * step_y);
                let pos = start_pos + offset;
                let candidate = Rect::from_min_size(pos.to_pos2(), size);

                if !self.blocks.iter().any(|b| b.rect.intersects(candidate)) {
                    return pos;
                }
            }
        }

        // Fallback: place with simple offset
        start_pos + Vec2::new(step_x, 0.0)
    }

    fn pause_oldest_animation(&mut self) {
        let mut oldest_idx = None;
        let mut oldest_time = f64::INFINITY;
        for (i, block) in self.blocks.iter().enumerate() {
            if let BlockContent::Image { playing, playing_start_time, .. } = &block.content {
                if *playing {
                    if let Some(start) = playing_start_time {
                        if *start < oldest_time {
                            oldest_time = *start;
                            oldest_idx = Some(i);
                        }
                    }
                }
            }
        }
        if let Some(idx) = oldest_idx {
            if let BlockContent::Image { playing, animation_state, frame_delays, aspect_ratio, path, .. } = &mut self.blocks[idx].content {
                *playing = false;
                *animation_state = AnimationState::Paused {
                    total_frame_count: frame_delays.len(),
                    frame_durations: frame_delays.clone(),
                    aspect_ratio: *aspect_ratio,
                    path: path.clone().unwrap_or_default(),
                    format: image_decoder::ImageFormat::Avif, // dummy
                };
                self.current_concurrent_animations -= 1;
            }
        }
    }

    fn save_session(&self) {
        if let Some(mut path) = FileDialog::new().add_filter("JSON", &["json"]).save_file() {
            if path.extension().is_none() {
                path.set_extension("json");
            }

            let session = Session {
                viewport: ViewportData {
                    pan: [self.viewport.pan.x, self.viewport.pan.y],
                    zoom: self.viewport.zoom,
                },
                blocks: self
                    .blocks
                    .iter()
                    .map(|b| BlockData {
                        id: b.id,
                        rect: [b.rect.min.x, b.rect.min.y, b.rect.max.x, b.rect.max.y],
                        chained: b.chained,
                        content: match &b.content {
                            BlockContent::Text { text } => {
                                BlockContentData::Text { text: text.clone() }
                            }
                            BlockContent::Image {
                                path,
                                counter,
                                playing,
                                ..
                            } => BlockContentData::Image {
                                path: path.clone().unwrap_or_default(),
                                counter: *counter,
                                playing: *playing,
                            },
                        },
                    })
                    .collect(),
            };

            if let Ok(file) = File::create(path) {
                let _ = serde_json::to_writer_pretty(file, &session);
            }
        }
    }

    fn reset_all_counters(&mut self) {
        for block in &mut self.blocks {
            if let BlockContent::Image { counter, .. } = &mut block.content {
                *counter = 0;
            }
        }
    }

    fn load_session(&mut self) {
        if let Some(path) = FileDialog::new().add_filter("JSON", &["json"]).pick_file() {
            if let Ok(file) = File::open(path) {
                if let Ok(session) = serde_json::from_reader::<_, Session>(BufReader::new(file)) {
                    self.viewport.pan = Vec2::new(session.viewport.pan[0], session.viewport.pan[1]);
                    self.viewport.zoom = session.viewport.zoom;
                    self.blocks.clear();

                    for b_data in session.blocks {
                        let rect = Rect::from_min_max(
                            Pos2::new(b_data.rect[0], b_data.rect[1]),
                            Pos2::new(b_data.rect[2], b_data.rect[3]),
                        );

                        let content = match b_data.content {
                            BlockContentData::Text { text } => BlockContent::Text { text },
                            BlockContentData::Image {
                                path,
                                counter,
                                playing,
                            } => {
                                // Trigger async load
                                if !path.is_empty() {
                                    self.load_image_file(
                                        PathBuf::from(&path),
                                        egui::Context::default(),
                                        Some(b_data.id),
                                    );
                                }
                                // Create placeholder
                                BlockContent::Image {
                                    frames: vec![],
                                    frame_delays: vec![],
                                    aspect_ratio: 1.0,
                                    playing,
                                    current_frame_idx: 0,
                                    last_frame_time: 0.0,
                                counter,
                                path: Some(path),
                                animation_state: AnimationState::Ready,
                                first_frame: None,
                                playing_start_time: None,
                            }
                            }
                        };

                        self.blocks.push(Block {
                            id: b_data.id,
                            rect,
                            content,
                            chained: b_data.chained,
                            selected: false,
                        });
                    }
                }
            }
        }
    }
}

impl BlockContent {
    fn as_text_mut(&mut self) -> Option<&mut String> {
        if let BlockContent::Text { text } = self {
            Some(text)
        } else {
            None
        }
    }
}

fn main() -> eframe::Result<()> {
    let options = eframe::NativeOptions::default();
    eframe::run_native(
        "MA Blocks",
        options,
        Box::new(|_cc| Ok(Box::new(CanvasApp::default()) as Box<dyn eframe::App>)),
    )
}
